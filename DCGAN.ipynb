{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DCGAN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"H59wX16bcgkd","colab_type":"code","outputId":"3995120c-7005-4de6-dac5-a536cb4ba7da","executionInfo":{"status":"ok","timestamp":1558100476244,"user_tz":-540,"elapsed":4270,"user":{"displayName":"박성진","photoUrl":"","userId":"15804894431305555430"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive',force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BntA-hACdCRM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"545207e1-0b86-43bc-f893-c3c87458fb6b","executionInfo":{"status":"ok","timestamp":1558100424374,"user_tz":-540,"elapsed":1358,"user":{"displayName":"박성진","photoUrl":"","userId":"15804894431305555430"}}},"source":[""],"execution_count":2,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ch_aQh80dEYD","colab_type":"code","outputId":"7a07611a-3118-4df2-da17-da4af650c9c7","executionInfo":{"status":"ok","timestamp":1558100505066,"user_tz":-540,"elapsed":4781,"user":{"displayName":"박성진","photoUrl":"","userId":"15804894431305555430"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["!pip install tensorboardx"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardx in /usr/local/lib/python3.6/dist-packages (1.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (1.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (1.16.3)\n","Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (3.7.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardx) (41.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xdxwVLAzdUoc","colab_type":"code","colab":{}},"source":["\n","\"\"\"utils.py\n","\n","Automatically generated by Colaboratory.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/1kQZ1iuvC0sDbmN7JIJZjm5R_sqtBlCXa\n","\"\"\"\n","\n","import numpy as np\n","import errno\n","import torchvision.utils as vutils\n","from tensorboardX import SummaryWriter\n","from IPython import display\n","from matplotlib import pyplot as plt\n","import torch\n","\n","'''\n","    TensorBoard Data will be stored in './runs' path\n","'''\n","\n","\n","class Logger:\n","\n","    def __init__(self, model_name, data_name):\n","        self.model_name = model_name\n","        self.data_name = data_name\n","\n","        self.comment = '{}_{}'.format(model_name, data_name)\n","        self.data_subdir = '{}/{}'.format(model_name, data_name)\n","\n","        # TensorBoard\n","        self.writer = SummaryWriter(comment=self.comment)\n","\n","    def log(self, d_error, g_error, epoch, n_batch, num_batches):\n","\n","        # var_class = torch.autograd.variable.Variable\n","        if isinstance(d_error, torch.autograd.Variable):\n","            d_error = d_error.data.cpu().numpy()\n","        if isinstance(g_error, torch.autograd.Variable):\n","            g_error = g_error.data.cpu().numpy()\n","\n","        step = Logger._step(epoch, n_batch, num_batches)\n","        self.writer.add_scalar(\n","            '{}/D_error'.format(self.comment), d_error, step)\n","        self.writer.add_scalar(\n","            '{}/G_error'.format(self.comment), g_error, step)\n","\n","    def log_images(self, images, num_images, epoch, n_batch, num_batches, format='NCHW', normalize=True):\n","        '''\n","        input images are expected in format (NCHW)\n","        '''\n","        if type(images) == np.ndarray:\n","            images = torch.from_numpy(images)\n","        \n","        if format=='NHWC':\n","            images = images.transpose(1,3)\n","        \n","\n","        step = Logger._step(epoch, n_batch, num_batches)\n","        img_name = '{}/images{}'.format(self.comment, '')\n","\n","        # Make horizontal grid from image tensor\n","        horizontal_grid = vutils.make_grid(\n","            images, normalize=normalize, scale_each=True)\n","        # Make vertical grid from image tensor\n","        nrows = int(np.sqrt(num_images))\n","        grid = vutils.make_grid(\n","            images, nrow=nrows, normalize=True, scale_each=True)\n","\n","        # Add horizontal images to tensorboard\n","        self.writer.add_image(img_name, horizontal_grid, step)\n","\n","        # Save plots\n","        self.save_torch_images(horizontal_grid, grid, epoch, n_batch)\n","\n","    def save_torch_images(self, horizontal_grid, grid, epoch, n_batch, plot_horizontal=True):\n","        out_dir = './data/images/{}'.format(self.data_subdir)\n","        Logger._make_dir(out_dir)\n","\n","        # Plot and save horizontal\n","        fig = plt.figure(figsize=(16, 16))\n","        plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n","        plt.axis('off')\n","        if plot_horizontal:\n","            display.display(plt.gcf())\n","        self._save_images(fig, epoch, n_batch, 'hori')\n","        plt.close()\n","\n","        # Save squared\n","        fig = plt.figure()\n","        plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n","        plt.axis('off')\n","        self._save_images(fig, epoch, n_batch)\n","        plt.close()\n","\n","    def _save_images(self, fig, epoch, n_batch, comment=''):\n","        out_dir = './data/images/{}'.format(self.data_subdir)\n","        Logger._make_dir(out_dir)\n","        fig.savefig('{}/{}_epoch_{}_batch_{}.png'.format(out_dir,\n","                                                         comment, epoch, n_batch))\n","\n","    def display_status(self, epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake):\n","        \n","        # var_class = torch.autograd.variable.Variable\n","        if isinstance(d_error, torch.autograd.Variable):\n","            d_error = d_error.data.cpu().numpy()\n","        if isinstance(g_error, torch.autograd.Variable):\n","            g_error = g_error.data.cpu().numpy()\n","        if isinstance(d_pred_real, torch.autograd.Variable):\n","            d_pred_real = d_pred_real.data\n","        if isinstance(d_pred_fake, torch.autograd.Variable):\n","            d_pred_fake = d_pred_fake.data\n","        \n","        \n","        print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(\n","            epoch,num_epochs, n_batch, num_batches)\n","             )\n","        print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n","        print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n","\n","    def save_models(self, generator, discriminator, epoch):\n","        out_dir = './data/models/{}'.format(self.data_subdir)\n","        Logger._make_dir(out_dir)\n","        torch.save(generator.state_dict(),\n","                   '{}/G_epoch_{}'.format(out_dir, epoch))\n","        torch.save(discriminator.state_dict(),\n","                   '{}/D_epoch_{}'.format(out_dir, epoch))\n","\n","    def close(self):\n","        self.writer.close()\n","\n","    # Private Functionality\n","\n","    @staticmethod\n","    def _step(epoch, n_batch, num_batches):\n","        return epoch * num_batches + n_batch\n","\n","    @staticmethod\n","    def _make_dir(directory):\n","        try:\n","            os.makedirs(directory)\n","        except OSError as e:\n","            if e.errno != errno.EEXIST:\n","                raise"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PooXmF_udEa1","colab_type":"code","colab":{}},"source":["from IPython import display\n","import torch\n","from torch import nn\n","from torch.optim import Adam\n","from torch.autograd import Variable\n","from torchvision import transforms, datasets\n","import os\n","os.chdir(\"/root/dataset\")\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PBfk2EtweZBD","colab_type":"text"},"source":["# cifar 10 data set"]},{"cell_type":"code","metadata":{"id":"XelZwIm2eMSC","colab_type":"code","colab":{}},"source":["\n","# CIFAR 10은 크기가 32 x 32인 이미지 DCGAN의 경우 일반적으로 64 x 64의 이미지를 사용합니다. 따라서 크기를 맞춰주기 위해 Scale을 해줍니다.\n","def cifar_data():\n","    compose = transforms.Compose(\n","        [\n","            transforms.Resize(64),\n","            transforms.ToTensor(),\n","            transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n","        ])\n","    return datasets.CIFAR10(root='/root/dataset', train=True, transform=compose, download=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Qgxq3M-eSwP","colab_type":"code","outputId":"1d58cb19-77c7-408c-f7a1-02807bc73b0d","executionInfo":{"status":"ok","timestamp":1558106541014,"user_tz":-540,"elapsed":1840,"user":{"displayName":"박성진","photoUrl":"","userId":"15804894431305555430"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data = cifar_data()\n","batch_size = 100\n","data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n","num_batches = len(data_loader)"],"execution_count":54,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KrbhTH-Eew6t","colab_type":"text"},"source":["# NETWORK"]},{"cell_type":"markdown","metadata":{"id":"DOPs5-2U9B-3","colab_type":"text"},"source":["## Discriminator"]},{"cell_type":"code","metadata":{"id":"ZpPgp3nnewmS","colab_type":"code","colab":{}},"source":["# Discriminator는 이미지를 입력받아 이미지가 진짜인지 가짜인지 출력한다.\n","class DiscriminativeNet(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super(DiscriminativeNet, self).__init__()\n","        \n","        self.conv1 = nn.Sequential( # 3*64*64 -> 64*32*32\n","            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True)\n","        )\n","        \n","        self.conv2 = nn.Sequential( # 64*32*32 -> 128*16*16\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4,stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2, inplace=True)\n","        )\n","        \n","        self.conv3 = nn.Sequential( # 128*16*16 -> 256*8*8\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4,stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(0.2, inplace=True)\n","        ) \n","        self.conv4 = nn.Sequential( # 256*8*8 - > 512*4*4\n","            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4,stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(0.2, inplace=True)\n","        )\n","        self.conv5=nn.Sequential( #512*4*4 -> 1\n","            nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4,stride=1, padding=0, bias=False),\n","            nn.Sigmoid()\n","        )\n","            \n","    def forward(self, x):\n","        # Convolutional layers\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7mswVlt49EqO","colab_type":"text"},"source":["## Generator"]},{"cell_type":"code","metadata":{"id":"jpj0MCk19EUk","colab_type":"code","colab":{}},"source":["class GenerativeNet(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super(GenerativeNet, self).__init__()\n","        \n","        self.conv1 = nn.Sequential( \n","                nn.ConvTranspose2d(in_channels=100, out_channels=512, kernel_size=4,stride=1, padding=0, bias=False),\n","                nn.BatchNorm2d(512),\n","                nn.ReLU(inplace=True)\n","        )       #100,100 -> 512,4,4\n","        \n","        self.conv2 = nn.Sequential( \n","                nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4,stride=2, padding=1, bias=False),\n","                nn.BatchNorm2d(256),\n","                nn.ReLU(inplace=True)\n","        )       #512*4*4 -> 256*8*8\n","        self.conv3 = nn.Sequential(\n","                nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4,stride=2, padding=1, bias=False),\n","                nn.BatchNorm2d(128),\n","                nn.ReLU(inplace=True)\n","        )       #256*8*8 -> 128*16*16\n","        self.conv4 = nn.Sequential(# 128*16*16 -> 64*32*32\n","                nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4,stride=2, padding=1, bias=False),\n","                nn.BatchNorm2d(64),\n","                nn.ReLU(inplace=True)\n","        )       # 128*16*16 -> 64*32*32\n","                \n","        self.conv5 = nn.Sequential(# 64*32*32 -> 3*64*64\n","                nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=4,stride=2, padding=1, bias=False),\n","                nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        # Convolutional layers\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sr7cncMhemjb","colab_type":"code","colab":{}},"source":["# Noise\n","def noise(size):\n","    n = Variable(torch.randn(size, 100,1,1))\n","    if torch.cuda.is_available(): return n.cuda()\n","    return n\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5I9n5art9Jha","colab_type":"code","colab":{}},"source":["'''\n","weigth의 초기값을 설정해주는 코드입니다. \n","Convloution layer의 경우 평균이 0, 표준편차가 0.02인 정규분포에서, \n","Batch normalization의 경우 평균은 1.0 표준편차는 0.02인 layer에서 값을 뽑아냅니다.\n","'''\n","\n","        \n","def init_weights(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:         # Conv weight init\n","        m.weight.data.normal_(0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:  # BatchNorm weight init\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"so5NJpFS9YzI","colab_type":"code","outputId":"37c93d28-b8b2-4f53-9d3c-35ebee6e8f9b","executionInfo":{"status":"ok","timestamp":1558106721648,"user_tz":-540,"elapsed":1358,"user":{"displayName":"박성진","photoUrl":"","userId":"15804894431305555430"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Create Network instances and init weights\n","print(\"G\")\n","generator = GenerativeNet()\n","generator.apply(init_weights)\n","\n","print(\"D\")\n","discriminator = DiscriminativeNet()\n","discriminator.apply(init_weights)\n","\n","# Enable cuda if available\n","if torch.cuda.is_available():\n","    generator.cuda()\n","    discriminator.cuda()"],"execution_count":74,"outputs":[{"output_type":"stream","text":["G\n","D\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ciVeDnlv_Enu","colab_type":"text"},"source":["# Optimization"]},{"cell_type":"code","metadata":{"id":"7eQaP9bJ_EXk","colab_type":"code","colab":{}},"source":["# Optimizers\n","d_optimizer = Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","g_optimizer = Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","# Loss function\n","loss = nn.BCELoss()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G2fmV_sQ_PcO","colab_type":"text"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"sxOMb9rE9fxX","colab_type":"code","colab":{}},"source":["def real_data_target(size):\n","    '''\n","    Tensor containing ones, with shape = size\n","    '''\n","    data = Variable(torch.ones(size, 1))\n","    if torch.cuda.is_available(): return data.cuda()\n","    return data\n","\n","def fake_data_target(size):\n","    '''\n","    Tensor containing zeros, with shape = size\n","    '''\n","    data = Variable(torch.zeros(size, 1))\n","    if torch.cuda.is_available(): return data.cuda()\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SwXNewqP_Sh1","colab_type":"code","colab":{}},"source":["\n","def train_discriminator(optimizer, real_data, fake_data):\n","    # Reset gradients\n","    optimizer.zero_grad()\n","    \n","    # 1.1 Train on Real Data\n","    prediction_real = discriminator(real_data)\n","    # Calculate error and backpropagate\n","    error_real = loss(prediction_real, real_data_target(real_data.size(0)))\n","    error_real.backward()\n","\n","    # 1.2 Train on Fake Data\n","    prediction_fake = discriminator(fake_data)\n","    # Calculate error and backpropagate\n","    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0)))\n","    error_fake.backward()\n","    \n","    # 1.3 Update weights with gradients\n","    optimizer.step()\n","    \n","    # Return error\n","    return error_real + error_fake, prediction_real, prediction_fake\n","\n","def train_generator(optimizer, fake_data):\n","    # 2. Train Generator\n","    # Reset gradients\n","    optimizer.zero_grad()\n","    # Sample noise and generate fake data\n","    prediction = discriminator(fake_data)\n","    # Calculate error and backpropagate\n","    error = loss(prediction, real_data_target(prediction.size(0)))\n","    error.backward()\n","    # Update weights with gradients\n","    optimizer.step()\n","    # Return error\n","    return error"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VWu4_9ID_bM1","colab_type":"text"},"source":["### Generate Samples for Testing"]},{"cell_type":"code","metadata":{"id":"pcWcgffE_YHs","colab_type":"code","colab":{}},"source":["num_test_samples = 16\n","test_noise = noise(num_test_samples)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJWOytlc_d53","colab_type":"code","outputId":"9e3e719e-4fd7-480a-a227-9612402e11ee","colab":{"base_uri":"https://localhost:8080/","height":3492,"output_embedded_package_id":"1SbjSYFKY4KZgD1TKbl819GlfXApfiCot"}},"source":["logger = Logger(model_name='DCGAN', data_name='CIFAR10')\n","# Number of epochs\n","num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","    for n_batch, (real_batch,_) in enumerate(data_loader):\n","        ############################\n","        # 1. Train Discriminator\n","        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","        # train with real\n","        # Generate fake data and detach \n","        # (so gradients are not calculated for generator)\n","        real_data = Variable(real_batch)\n","        if torch.cuda.is_available(): real_data = real_data.cuda()\n","            \n","        # Generate fake data\n","        fake_data = generator(noise(real_data.size(0))).detach()\n","        # Train D  with fake\n","        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer, \n","                                                                real_data, fake_data)\n","\n","        # 2. Train Generator\n","        # Generate fake data\n","        # Update G network: maximize log(D(G(z)))\n","        fake_data = generator(noise(real_batch.size(0)))\n","        # Train G\n","        g_error = train_generator(g_optimizer, fake_data)\n","        # Log error\n","        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n","        \n","        # Display Progress\n","        if (n_batch) % 100 == 0:\n","            \n","            # Display Images\n","            test_images = generator(test_noise).data.cpu()\n","            logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);\n","            # Display status Logs\n","            logger.display_status(\n","                epoch, num_epochs, n_batch, num_batches,\n","                d_error, g_error, d_pred_real, d_pred_fake\n","            )\n","        # Model Checkpoints\n","        logger.save_models(generator, discriminator, epoch)\n","        \n","        \n","\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"SlACi5MYSFgm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}